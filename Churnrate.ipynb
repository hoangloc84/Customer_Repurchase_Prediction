{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHURN RATE PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['LOKY_MAX_CPU_COUNT'] = '10'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features_and_target(file_path='cleaned_retail_data.csv'):\n",
    "    # READ DATA\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n",
    "    # SPLIT DATA \n",
    "    holdout_start_date = df['InvoiceDate'].max() - timedelta(days=30)\n",
    "    df_development = df[df['InvoiceDate'] < holdout_start_date].copy()\n",
    "    df_holdout = df[df['InvoiceDate'] >= holdout_start_date].copy()\n",
    "\n",
    "    # FEATURE ENGINEERING\n",
    "    snapshot_date_dev = df_development['InvoiceDate'].max() + timedelta(days=1)\n",
    "    # RFM\n",
    "    features = df_development.groupby('CustomerID').agg(\n",
    "        Recency=('InvoiceDate', lambda x: (snapshot_date_dev - x.max()).days),\n",
    "        Frequency=('InvoiceNo', 'nunique'),\n",
    "        Monetary=('TotalPrice', 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    # AVG BASKET VALUE\n",
    "    avg_basket_value = df_development.groupby('CustomerID')['TotalPrice'].sum() / df_development.groupby('CustomerID')['InvoiceNo'].nunique()\n",
    "    avg_basket_value = avg_basket_value.reset_index(name='avg_basket_value')\n",
    "\n",
    "    # DISC PRODUCT\n",
    "    distinct_products = df_development.groupby('CustomerID')['StockCode'].nunique().reset_index(name='distinct_products')\n",
    "\n",
    "    # AVG BETWEEN DAY PURCHASE\n",
    "    df_dev_sorted = df_development.sort_values(by=['CustomerID', 'InvoiceDate'])\n",
    "    df_dev_sorted['days_between'] = df_dev_sorted.groupby('CustomerID')['InvoiceDate'].diff().dt.days\n",
    "    avg_days_between = df_dev_sorted.groupby('CustomerID')['days_between'].mean().reset_index(name='avg_days_between_purchases')\n",
    "\n",
    "    # MERGING\n",
    "    features = pd.merge(features, avg_basket_value, on='CustomerID', how='left')\n",
    "    features = pd.merge(features, distinct_products, on='CustomerID', how='left')\n",
    "    features = pd.merge(features, avg_days_between, on='CustomerID', how='left')\n",
    "    features.fillna(0, inplace=True) # Điền 0 cho các giá trị NaN\n",
    "\n",
    "    # CREATE TARGET\n",
    "    customers_in_holdout = df_holdout['CustomerID'].unique()\n",
    "    features['will_buy'] = features['CustomerID'].isin(customers_in_holdout).astype(int)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training & Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_model(features):\n",
    "    # Chuẩn bị dữ liệu X, y ban đầu (chưa có feature cluster)\n",
    "    X = features[['Recency', 'Frequency', 'Monetary', 'avg_basket_value', 'distinct_products', 'avg_days_between_purchases']]\n",
    "    y = features['will_buy']\n",
    "    \n",
    "    # Chia train/test TRƯỚC KHI làm clustering\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # K-MEANS\n",
    "    rfm_cols = ['Recency', 'Frequency', 'Monetary']\n",
    "\n",
    "    scaler_kmeans = StandardScaler()\n",
    "    X_train_rfm_scaled = scaler_kmeans.fit_transform(X_train[rfm_cols])\n",
    "    X_test_rfm_scaled = scaler_kmeans.transform(X_test[rfm_cols])\n",
    "\n",
    "    k = 10\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_train_rfm_scaled)\n",
    "\n",
    "    X_train['RFM_Cluster'] = kmeans.predict(X_train_rfm_scaled)\n",
    "    X_test['RFM_Cluster'] = kmeans.predict(X_test_rfm_scaled)\n",
    "    \n",
    "    train_distances = kmeans.transform(X_train_rfm_scaled)\n",
    "    X_train['Distance_to_Centroid'] = train_distances[np.arange(len(train_distances)), X_train['RFM_Cluster']]\n",
    "    \n",
    "    test_distances = kmeans.transform(X_test_rfm_scaled)\n",
    "    X_test['Distance_to_Centroid'] = test_distances[np.arange(len(test_distances)), X_test['RFM_Cluster']]\n",
    "\n",
    "    # RF\n",
    "    best_params = {\n",
    "        'n_estimators': 500, 'max_depth': 5, 'min_samples_leaf': 4,\n",
    "        'class_weight': 'balanced', 'random_state': 42, 'n_jobs': 10\n",
    "    }\n",
    "    rf_model = RandomForestClassifier(**best_params)\n",
    "    rf_model.fit(X_train, y_train)\n",
    "\n",
    "    # LR\n",
    "    scaler_lr = StandardScaler()\n",
    "    X_train_scaled = scaler_lr.fit_transform(X_train)\n",
    "    X_test_scaled = scaler_lr.transform(X_test)\n",
    "    lr_model = LogisticRegression(random_state=42, class_weight='balanced', max_iter=1000)\n",
    "    lr_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # RESULT\n",
    "    print(f\"{best_params}\")\n",
    "    # RF\n",
    "    print(\"----- RF -----\")\n",
    "    y_pred_rf = rf_model.predict(X_test)\n",
    "    y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]\n",
    "    print(classification_report(y_test, y_pred_rf, target_names=['NO(0)', 'YES(1)'])) \n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.3f}\")\n",
    "    print(f\"AUC-ROC Score: {roc_auc_score(y_test, y_pred_proba_rf):.3f}\")\n",
    "\n",
    "    # LR\n",
    "    print(\"\\n----- LR -----\")\n",
    "    y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "    y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
    "    print(classification_report(y_test, y_pred_lr, target_names=['NO(0)', 'YES(1)']))\n",
    "    print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr):.3f}\")\n",
    "    print(f\"AUC-ROC Score: {roc_auc_score(y_test, y_pred_proba_lr):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 500, 'max_depth': 5, 'min_samples_leaf': 4, 'class_weight': 'balanced', 'random_state': 42, 'n_jobs': 10}\n",
      "----- RF -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       NO(0)       0.79      0.75      0.77       538\n",
      "      YES(1)       0.56      0.62      0.59       276\n",
      "\n",
      "    accuracy                           0.70       814\n",
      "   macro avg       0.67      0.68      0.68       814\n",
      "weighted avg       0.71      0.70      0.71       814\n",
      "\n",
      "Accuracy: 0.704\n",
      "AUC-ROC Score: 0.740\n",
      "\n",
      "----- LR -----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       NO(0)       0.78      0.77      0.77       538\n",
      "      YES(1)       0.56      0.58      0.57       276\n",
      "\n",
      "    accuracy                           0.71       814\n",
      "   macro avg       0.67      0.68      0.67       814\n",
      "weighted avg       0.71      0.71      0.71       814\n",
      "\n",
      "Accuracy: 0.705\n",
      "AUC-ROC Score: 0.735\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    customer_features = prepare_features_and_target(file_path='cleaned_retail_data.csv')\n",
    "    train_and_evaluate_model(customer_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the Random Forest (RF) and Logistic Regression (LR) models are effective at predicting which customers will return. However, the Random Forest model is slightly better and is the recommended choice.\n",
    "\n",
    "Key Metrics Explained\n",
    "- AUC-ROC Score: This measures how well a model can distinguish between a customer who will return and one who will not. A higher score is better.\n",
    "\n",
    "    + RF (0.740) is slightly better at telling these two groups apart than LR (0.735).\n",
    "\n",
    "- Recall (for \"YES\"): This is the most important metric for this problem. It answers the question: \"Of all the customers who actually returned, what percentage did our model correctly find?\"\n",
    "\n",
    "    + RF (0.62): Correctly identified 62% of all returning customers.\n",
    "\n",
    "    + LR (0.58): Only found 58% of all returning customers.\n",
    "\n",
    "    --> Conclusion: The Random Forest model is significantly better at finding potential opportunities and helps you miss fewer valuable customers.\n",
    "\n",
    "- Precision (for \"YES\"): This answers the question: \"When our model predicts a customer will return, how often is it correct?\"\n",
    "\n",
    "    + RF (0.56) & LR (0.56): Both models are equally precise. When they flag a customer, they are correct 56% of the time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
